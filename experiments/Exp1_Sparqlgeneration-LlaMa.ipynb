{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c1ec5f4-551b-4435-bdb3-985a13d870d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating SPARQL using Code LlaMa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517c7bd-88b3-49e7-9221-20c9a6880acc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup of Code LLaMa 34B Quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c8b05ba-8e2b-4ae8-a66c-54ad8c8174aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 824/824 [00:00<00:00, 4.70MB/s]\n",
      "tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 12.0MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 4.05MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 411/411 [00:00<00:00, 1.08MB/s]\n",
      "config.json: 100%|██████████| 1.25k/1.25k [00:00<00:00, 9.85MB/s]\n",
      "configuration_llama.py: 100%|██████████| 8.56k/8.56k [00:00<00:00, 19.0MB/s]\n",
      "quantize_config.json: 100%|██████████| 187/187 [00:00<00:00, 838kB/s]\n",
      "model.safetensors: 100%|██████████| 18.3G/18.3G [02:01<00:00, 150MB/s] \n",
      "modeling_llama.py: 100%|██████████| 45.9k/45.9k [00:00<00:00, 521kB/s]\n",
      "skip module injection for FusedLlamaMLPForQuantizedModel not support integrate without triton yet.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline, logging\n",
    "from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
    "import time\n",
    "\n",
    "#model_name_or_path = \"TheBloke/Llama-2-7b-Chat-GPTQ\"\n",
    "model_name_or_path = \"TheBloke/CodeLlama-34B-Instruct-GPTQ\"\n",
    "model_basename = \"model\"\n",
    "\n",
    "use_triton = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "model = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\n",
    "        model_basename=model_basename,\n",
    "        use_safetensors=True,\n",
    "        trust_remote_code=True,\n",
    "        device=\"cuda:0\",\n",
    "        skip_special_tokens= True, \n",
    "        use_triton=use_triton,        \n",
    "        quantize_config=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c80baa-7814-409a-9be8-4aa7d941fe79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prevent printing spurious transformers error when using pipeline with AutoGPTQ\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    use_cache=True,\n",
    "    device_map=\"auto\",    \n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    temperature=0.1,\n",
    "    max_length=300,\n",
    "    repetition_penalty=1.1,  \n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7288ebae-d15a-43ad-9555-210d51d34353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction= \"\"\"\n",
    "You are given an input question, convert it to SPARQL code to query for Wikidata. Please wrap your code answer using ```:\n",
    "\"\"\"\n",
    "    \n",
    "def generate_sparql(question): \n",
    "    \n",
    "    sparql_prompt=f'''[INST] {instruction} {question} [/INST]'''\n",
    "    \n",
    "    #response=pipe(sparql_prompt)\n",
    "    response = pipe(sparql_prompt)[0]['generated_text']\n",
    "    #print(response)\n",
    "    #sparql= response[0][\"generated_text\"].split(\"<</SYS>>\")[1]\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "12c89b5f-50b4-45b2-953a-ba7f96741521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#generate_sparql(\"Who is the country for head of state of Mahmoud Abbas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922ccaf6-0920-4190-8bea-5208e730a54d",
   "metadata": {},
   "source": [
    "### Importing Dataset 1 QALD 9 Test and converting to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "327866a6-4b92-4249-8ad1-13af117c2a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('data/test.json', orient='records')\n",
    "df['id'] = range(1, len(df) + 1)\n",
    "df.rename(columns={'en_ques': 'questions', 'sparql': 'sparql_qald', 'fil_sparql': 'sparql_gen'}, inplace=True)\n",
    "df = df[['id', 'questions', 'sparql_qald', 'sparql_gen']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d3ba2-5b91-4209-a991-59512b15702e",
   "metadata": {},
   "source": [
    "#### Running Experiment 1 for Dataset 1 Qald9 Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73d23a63-3541-4495-ae34-90fc2938b8bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9173a65-f9ab-41f7-881b-1432478cd77a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/upb/users/m/manzoor/profiles/unix/cs/.conda/envs/sparqlgen/lib/python3.10/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 2070.9248554706573 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df['output'] = df['questions'].apply(generate_sparql)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3721cec9-c0c7-4868-8179-1398c972b114",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[INST] \\nYou are given an input question, convert it to SPARQL code to query for DBpedia. Please wrap your code answer using ```:\\n what is the time zone of salt lake city? [/INST]  Here\\'s the SPARQL query to find the time zone of Salt Lake City:\\n```sql\\nPREFIX dbpedia-owl: <http://dbpedia.org/ontology/>\\nSELECT DISTINCT?timeZone\\nWHERE {\\n ?city rdf:type dbpedia-owl:City.\\n ?city dbpedia-owl:name \"Salt Lake City\"@en.\\n ?city dbpedia-owl:timeZone?timeZone.\\n}\\n```\\nThis query uses the `rdf:type` and `dbpedia-owl:name` properties to identify the specific city we\\'re interested in (Salt Lake City), and then uses the `dbpedia-owl:timeZone` property to retrieve the time zone information associated with that city. The `DISTINCT` keyword is used to remove any duplicate results from the output.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['output'].head()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63a6f69c-088b-451e-9c93-78102bba0ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('Output/exp1_prompt_output_qald.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56202bd2-870a-486e-a5cd-32d33f4b9475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "#nltk.download('punkt')\n",
    "\n",
    "for index, row in df_lcquad.iterrows():\n",
    "    \n",
    "    reference = nltk.word_tokenize(row['sparql_lcquad'].lower())\n",
    "    if len(row['output_cleaned']) < 1:\n",
    "        print(index)\n",
    "        continue\n",
    "    candidate = nltk.word_tokenize(row['output_cleaned'][0].lower())\n",
    "    bleu_score = sentence_bleu([reference], candidate[1:])\n",
    "    df_lcquad.at[index, 'Org_bleu_score'] = bleu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cbc36726-b9e3-47fe-84f2-67caf7eb597f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    prefix_index = text.find('PREFIX')\n",
    "    last_bracket_index = text.rfind(']')\n",
    "    \n",
    "    if prefix_index != -1 and last_bracket_index != -1:\n",
    "        content_between = text[prefix_index:last_bracket_index].strip()\n",
    "        clean_content = re.sub(r'^\\[\\'sql|\\'\\]$', '', content_between).strip()\n",
    "\n",
    "        return clean_content\n",
    "    else:\n",
    "        print(\"No match found.\")\n",
    "        return \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3479e052-c648-4e71-b0c3-5f68219c328b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_bleu = df['Org_bleu_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "024e1b13-8e15-4964-aa01-171ac783fe8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08278954133622182"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_bleu ### Without any postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "513ce929-56cf-4f58-ba6c-dea631b4c408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_content(text):\n",
    "    parts = text.split('[/INST]')\n",
    "    if len(parts) > 1:\n",
    "        matches = re.findall(r'```(.*?)```', parts[1], re.DOTALL)\n",
    "        return matches\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6f727eef-29f1-4b10-b234-3ef183cfe50e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['output_cleaned'] = df['output'].apply(lambda x: extract_content(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "81a3efd9-08a5-4e8f-94f4-577b77374cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('Output/exp1_prompt_outputcleaned_qald_pp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c91fcc-d075-4194-8256-5f3deab1a4c8",
   "metadata": {},
   "source": [
    "### Vquanda Experiment Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0bdab43d-8796-43e5-9492-b0b222fc37af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_vquad = pd.read_json('data/test_vquanda.json', orient='records')\n",
    "df_vquad.rename(columns={'en_ques': 'questions', 'sparql': 'sparql_vquanda'}, inplace=True)\n",
    "df_vquad = df_vquad[['questions', 'sparql_vquanda']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "31071aed-86d4-4eae-a5b9-0bac1e46b560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/upb/users/m/manzoor/profiles/unix/cs/.conda/envs/sparqlgen/lib/python3.10/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 8275.652656793594 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_vquad['output'] = df_vquad['questions'].apply(generate_sparql)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "77be07ad-c748-484c-9e35-e84804569c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_vquad.to_csv('Output/exp1_prompt_output_vquanda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6afccd2a-c975-41df-b1f0-7a20369c5cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_vquad['output_cleaned'] = df_vquad['output'].apply(lambda x: extract_content(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "368a76ac-2871-49f9-b222-c19ea9e394e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05610608613652875"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_bleu = df_vquad['Org_bleu_score'].mean()\n",
    "average_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7af0dfc2-fec4-4f6a-b80e-e3833ee02d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_vquad.to_csv('Output/exp1_prompt_outputcleaned_vquanda_pp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea1a25-cc57-4604-88b2-66ca9cd31c45",
   "metadata": {},
   "source": [
    "### lcquad Experiment Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "379096f2-9852-4794-85f8-56ac8553ae0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lcquad = pd.read_json('data/test_lcquad2.json', orient='records')\n",
    "df_lcquad.rename(columns={'question': 'questions', 'sparql_wikidata': 'sparql_lcquad'}, inplace=True)\n",
    "df_lcquad = df_lcquad[['questions', 'sparql_lcquad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "11d8c797-31d5-47e6-ba8f-0b07d3f0ac21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/upb/users/m/manzoor/profiles/unix/cs/.conda/envs/sparqlgen/lib/python3.10/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 56246.60027384758 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_lcquad['output'] = df_lcquad['questions'].apply(generate_sparql)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d2e09ccb-4bec-48c9-a1cd-6be569dec016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lcquad.to_csv('Output/exp1_prompt_output_lcquad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "896580df-02c5-409b-9334-8b379f4eba53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lcquad['output_cleaned'] = df_lcquad['output'].apply(lambda x: extract_content(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6aa33ec4-77c7-40e9-be01-72ce8a3b54c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06574901938786067"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_bleu = df_lcquad['Org_bleu_score'].mean()\n",
    "average_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6e8f2fe4-4609-4aa0-8465-e2ee4f6d5c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lcquad.to_csv('Output/exp1_prompt_outputcleaned_lcquad_pp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c251b742-d29d-497b-8f1f-a9cfb8748b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9715bbf6-9a60-4f58-9933-2b8f4c9ee052",
   "metadata": {},
   "source": [
    "### Extra Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparqlgen",
   "language": "python",
   "name": "sparqlgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
